{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    " def read_json(filename):\n",
    "    with open(filename) as f:\n",
    "        js_graph = json.load(f) #, default={'sender': 'source'})\n",
    "        _attrs = dict(source='sender', target='receiver', name='guid',\n",
    "              key='guid', link='links')\n",
    "    #return nx.readwrite.node_link_graph(js_graph, {'link': 'links', 'source': 'sender', 'target': 'receiver', 'key': 'guid'})\n",
    "    return nx.readwrite.node_link_graph(js_graph, directed=True, multigraph=False, attrs={'link': 'links', 'source': 'sender', 'target': 'receiver', 'key': 'guid', 'name': 'guid'} )\n",
    " \n",
    "# get the largest connected component\n",
    "def read_json_file(filename):\n",
    "    graph = read_json(filename)\n",
    "    return graph.subgraph(max(nx.weakly_connected_components(graph), key=len))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx \n",
    "import json\n",
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "from math import log10\n",
    "  \n",
    "def remove_edges(G_reduced, items, edges_max_goal):\n",
    "    current_time = time.time()\n",
    "    removed_edges = []\n",
    "    # sort edges by betweeness centrality lowest-to-highest\n",
    "    sorted_bet_cent_edges = sorted(items,reverse=False, key=lambda x: x[1])\n",
    "     \n",
    "    print(\"sorting took:\", time.time()-current_time)\n",
    "    to_remove = G_reduced.number_of_edges() - edges_max_goal\n",
    "    for bet_cent in sorted_bet_cent_edges:  \n",
    "        if (len(removed_edges) >= to_remove):\n",
    "            break\n",
    "        if G_reduced.degree(bet_cent[0]) > 2 and G_reduced.degree(bet_cent[1]) > 2:\n",
    "            G_reduced.remove_edge(bet_cent[0], bet_cent[1]) \n",
    "            removed_edges.append(bet_cent)\n",
    "\n",
    "    time_spent = time.time()-current_time\n",
    "    print(\"for loop took : \", time_spent)\n",
    "    G_reduced.remove_edges_from(removed_edges)\n",
    "\n",
    "    return G_reduced, removed_edges\n",
    " \n",
    "def postprocess(G_reduced, items):\n",
    "    number_wcc = nx.number_weakly_connected_components(G_reduced) \n",
    "    print(number_wcc)\n",
    "    if number_wcc == 1:\n",
    "        #print(\"****** already 1 component \")\n",
    "        return G_reduced\n",
    "\n",
    "    current_time = time.time() \n",
    "    _components = [c for c in nx.weakly_connected_components(G_reduced)]\n",
    "    \n",
    "    for edge in reversed(items): \n",
    "        if number_wcc == 1: \n",
    "            break\n",
    "            \n",
    "        for c in _components:\n",
    "            if edge[0] in c and edge[1] in c :\n",
    "                # edge is within one component\n",
    "                break\n",
    "            elif edge[0] in c or edge[1] in c : \n",
    "                # edge is connecting two components\n",
    "                G_reduced.add_edge(*edge)\n",
    "                _components = [c for c in nx.weakly_connected_components(G_reduced)]\n",
    "                number_wcc = len(_components) \n",
    "                break\n",
    "     \n",
    "    time_spent = time.time()-current_time\n",
    "    print(\"remove_edges took : \", time_spent)\n",
    "    return G_reduced  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_reduce(G, edges_max_goal, weight_attr):\n",
    "    bet_cent_edges = nx.edge_betweenness_centrality(G, weight=weight_attr)\n",
    " \n",
    "    G_reduced, removed_edges = remove_edges(G, bet_cent_edges, edges_max_goal) \n",
    "    G_reduced = postprocess(G_reduced, removed_edges)\n",
    "\n",
    "def edge_reduce_test(G, edge_cuts, weight_attr):\n",
    "    bet_cent_edges = nx.edge_betweenness_centrality(G, weight=weight_attr)\n",
    "    \n",
    "    total_weight = []\n",
    "\n",
    "    for edge_cut in edge_cuts:\n",
    "        edges_max_goal = G.number_of_edges() * edge_cut\n",
    "        G_reduced, removed_edges = remove_edges(G.copy(), bet_cent_edges, edges_max_goal) \n",
    "        G_reduced = postprocess(G_reduced, removed_edges)\n",
    "        \n",
    "        total_weight.append(G_reduced.size(weight=weight_attr)) \n",
    "\n",
    "    return edge_cuts, total_weight\n",
    "\n",
    "def edge_reduce_approximate(G, edges_max_goal, weight_attr): \n",
    "    c = 10\n",
    "    take_count = int(c * log10(nx.number_of_nodes(G)))\n",
    "    print(\"take_count\",take_count)\n",
    "\n",
    "    bet_cent_edges = nx.edge_betweenness_centrality(G, k=take_count, weight=weight_attr) \n",
    " \n",
    "    G_reduced, removed_edges = remove_edges(G, bet_cent_edges, edges_max_goal) \n",
    "    G_reduced = postprocess(G_reduced, removed_edges)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_reduce_approximate_test(filename, G, edge_cuts, weight_attr='transferred'):\n",
    "    c = 10\n",
    "    take_count = int(c * log10(nx.number_of_nodes(G)))\n",
    "    print(\"edge_betweenness_centrality\")\n",
    "\n",
    "    bet_cent_edges = nx.edge_betweenness_centrality(G, k=take_count, weight=weight_attr) \n",
    " \n",
    "    print(\"edge_betweenness_centrality done\")\n",
    "    total_weight = []\n",
    "    in_degree = []\n",
    "    out_degree = []\n",
    "    running_time = []\n",
    "    average_clustering = []\n",
    "    nn = []\n",
    "    ne = []\n",
    "    wcc = []\n",
    "\n",
    "    for edge_cut in edge_cuts:  \n",
    "        current_time = time.time()\n",
    "        edges_max_goal = G.number_of_edges() * edge_cut\n",
    "        print(\"copying:\")\n",
    "        graph = nx.DiGraph(G)\n",
    "        print(\"original number of edges:\", graph.number_of_edges())\n",
    "        \n",
    "        G_reduced, removed_edges = remove_edges(graph, bet_cent_edges, edges_max_goal)\n",
    "        G_reduced = postprocess(G_reduced, removed_edges) \n",
    "        time_spent = time.time()-current_time\n",
    "        \n",
    "        total_weight.append(G_reduced.size(weight=weight_attr))  \n",
    "        running_time.append(time_spent)\n",
    "        #average_clustering.append(nx.average_clustering(G_reduced.to_undirected(as_view=True)))\n",
    "\n",
    "        nn.append(G_reduced.number_of_nodes())\n",
    "        ne.append(G_reduced.number_of_edges())\n",
    "        wcc.append(nx.number_weakly_connected_components(G_reduced))\n",
    "\n",
    "        print(\"weight: \", G_reduced.size())\n",
    "        print(\"weight: \", G_reduced.size(weight=weight_attr)) \n",
    "\n",
    "    return edge_cuts, total_weight, average_clustering, nn, ne, wcc\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test_for_file(file_name, weight_attr):\n",
    "    graph = read_json_file(file_name) \n",
    "    print(nx.info(graph))\n",
    "    print(\"\")\n",
    "    edge_percentages = [0.03, 0.5, 1] \n",
    "    edge_cuts_2, total_weight_2, average_clustering2, nn2, ne2, wcc2  = edge_reduce_approximate_test(file_name, graph.copy(), edge_percentages, weight_attr)\n",
    "\n",
    "    print(\"edge_cuts_BC\", edge_cuts_2)\n",
    "    print(\"total_weight_BC\", total_weight_2) \n",
    "    print(\"wcc_BC\", wcc2)     \n",
    "    print(\"average_clustering_BC\", average_clustering2)\n",
    "    print(\"nn_BC\", nn2)\n",
    "    print(\"ne_BC\", ne2)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: \n",
      "Type: DiGraph\n",
      "Number of nodes: 400\n",
      "Number of edges: 9800\n",
      "Average in degree:  24.5000\n",
      "Average out degree:  24.5000\n",
      "\n",
      "edge_betweenness_centrality\n",
      "edge_betweenness_centrality done\n",
      "copying:\n",
      "original number of edges: 9800\n",
      "sorting took: 0.001827239990234375\n",
      "for loop took :  0.04661726951599121\n",
      "1\n",
      "weight:  503\n",
      "weight:  260020.0\n",
      "copying:\n",
      "original number of edges: 9800\n",
      "sorting took: 0.0018291473388671875\n",
      "for loop took :  0.05661511421203613\n",
      "1\n",
      "weight:  503\n",
      "weight:  260020.0\n",
      "copying:\n",
      "original number of edges: 9800\n",
      "sorting took: 0.0018897056579589844\n",
      "for loop took :  0.028668880462646484\n",
      "1\n",
      "weight:  4900\n",
      "weight:  2454422.0\n",
      "copying:\n",
      "original number of edges: 9800\n",
      "sorting took: 0.0027310848236083984\n",
      "for loop took :  0.0034351348876953125\n",
      "1\n",
      "weight:  9800\n",
      "weight:  4913264.0\n",
      "edge_cuts_BC [0.01, 0.03, 0.5, 1]\n",
      "total_weight_BC [260020.0, 260020.0, 2454422.0, 4913264.0]\n",
      "wcc_BC [1, 1, 1, 1]\n",
      "average_clustering_BC []\n",
      "nn_BC [400, 400, 400, 400]\n",
      "ne_BC [503, 503, 4900, 9800]\n"
     ]
    }
   ],
   "source": [
    "run_test_for_file(\"test_data/test_caveman_8_50.json\", \"lastTs\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
